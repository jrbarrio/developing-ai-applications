{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Completions\n",
    "\n",
    "Text most likely to complete a prompt. Response is non-deterministic (inherently random)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"Replace car with plane and adjust phrase:\n",
    "A car is a vehicle that is typically powered by an internal combustion engine or an electric motor. It has four wheels, and is designed to carry passengers and/or cargo on roads or highways. Cars have become a ubiquitous part of modern society, and are used for a wide variety of purposes, such as commuting, travel, and transportation of goods. Cars are often associated with freedom, independence, and mobility.\"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=prompt,\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling response randomness\n",
    "\n",
    "The ```temperature``` parameter imposes control on determinism. Ranges from 0 (highly deterministic) to 2 (very random)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"Summarize the following text into two concise bullet points:\n",
    "Investment refers to the act of committing money or capital to an enterprise with the expectation of obtaining an added income or profit in return. There are a variety of investment options available, including stocks, bonds, mutual funds, real estate, precious metals, and currencies. Making an investment decision requires careful analysis, assessment of risk, and evaluation of potential rewards. Good investments have the ability to produce high returns over the long term while minimizing risk. Diversification of investment portfolios reduces risk exposure. Investment can be a valuable tool for building wealth, generating income, and achieving financial security. It is important to be diligent and informed when investing to avoid losses.\"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=prompt,\n",
    "  max_tokens=400,\n",
    "  temperature=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content transformation\n",
    "\n",
    "Changing text based on an instruction\n",
    "- Find and replace\n",
    "- Summarization\n",
    "- Copyediting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Update name to Maarten, pronouns to he/him, and job title to Senior Content Developer:\n",
    "Joanne is a Content Developer at DataCamp. Her favorite programming language is R,\n",
    "which she uses for her statistical analyses.\n",
    "\"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=prompt\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=\"Create a slogan for a new restaurant\",\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)\n",
    "print(response.usage.total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling response length\n",
    "\n",
    "Using ```max_tokens``` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=\"Create a slogan for a new restaurant\",\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)\n",
    "print(response.usage.total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasification tasks\n",
    "\n",
    "Task that involves assigning a label to information:\n",
    "- Identifying the language from text\n",
    "- Categorization\n",
    "- Classify sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=\"Classify the following animals into categories: zebra, crocodile, blue whale, polar bear, salmon, dog.\",\n",
    "  max_tokens=50\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=\"Classify the following animals into animals with fur and without: zebra, crocodile, dolphin, polar bear, salmon, dog.\",\n",
    "  max_tokens=50\n",
    ")\n",
    "\n",
    "print(response.choices[0].text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Classify sentiment in the following statements:\n",
    "1. The service was very slow\n",
    "2. The steak was awfully tasty!\n",
    "3. Meal was decent, but I've had better.\n",
    "4. My food was delayed, but drinks were good.\n",
    "\"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=prompt,\n",
    "  max_tokens=50\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot vs. one-shot vs. few-shot prompting\n",
    "- Zero-shot prompting: no examples provided\n",
    "\n",
    "In-context learning:\n",
    "- One-shot prompting: one example provided\n",
    "- Few-shot prompting: a handful of examples provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Classify sentiment in the following statements:\n",
    "The service was very slow // Disgruntled\n",
    "Meal was decent, but I've had better. //\n",
    "\"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=prompt\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Classify sentiment in the following statements:\n",
    "The service was very slow // Disgruntled\n",
    "The steak was awfully tasty! // Delighted\n",
    "Good experience overall. // Satisfied\n",
    "Meal was decent, but I've had better. //\n",
    "\"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=prompt\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[{\"role\": \"system\",\n",
    "  \"content\": \"You are a data science tutor who speaks concisely.\"},\n",
    "  {\"role\": \"user\",\n",
    "  \"content\": \"What is the difference between mutable and immutable objects?\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-turn chat completions with ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat completions for single-turn tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "model=\"gpt-3.5-turbo\",\n",
    "messages=[\n",
    "  {\"role\": \"system\",\"content\": \"You are a data science tutor who speaks concisely.\"},\n",
    "  {\"role\": \"user\",\"content\": \"How do you define a Python list?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"Lists are defined by enclosing a comma-separated sequence of objects inside square brackets [ ].\"},\n",
    "  {\"role\": \"user\", \"content\": \"What is the difference between mutable and immutable objects?\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": \"You are a data science tutor who provides short, simple explanations.\"}]\n",
    "\n",
    "user_qs = [\"Why is Python so popular?\", \"Summarize this in one sentence.\"]\n",
    "\n",
    "for q in user_qs:\n",
    "  print(\"User: \", q)\n",
    "  user_dict = {\"role\": \"user\", \"content\": q}\n",
    "  messages.append(user_dict)\n",
    "  \n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages\n",
    "  )\n",
    "\n",
    "  assistant_dict = {\"role\": \"assistant\", \"content\": response.choices[0].message.content}\n",
    "  messages.append(assistant_dict)\n",
    "  print(\"Assistant: \", response.choices[0].message.content, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "working-with-openai-api-ccThAi0B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
