{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines with Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import GPT2Tokenizer, DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the task pipeline\n",
    "task_pipeline = pipeline(task=\"sentiment-analysis\")\n",
    "\n",
    "# Create the model pipeline\n",
    "model_pipeline = pipeline(model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "input = \"This course is pretty good, I guess.\"\n",
    "\n",
    "# Predict the sentiment\n",
    "task_output = task_pipeline(input)\n",
    "model_output = model_pipeline(input)\n",
    "\n",
    "print(f\"Sentiment from task_pipeline: {task_output[0]['label']}; Sentiment from model_pipeline: {model_output[0]['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AutoClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Create the pipeline\n",
    "sentimentAnalysis = pipeline(task=\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Predict the sentiment\n",
    "output = sentimentAnalysis(input)\n",
    "\n",
    "print(f\"Sentiment using AutoClasses: {output[0]['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing models with the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "distil_pipeline = pipeline(task=\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Predict the sentiment\n",
    "distil_output = distil_pipeline(input)\n",
    "\n",
    "# Create the second pipeline and predict the sentiment\n",
    "bert_pipeline = pipeline(task=\"sentiment-analysis\", model=\"kwang123/bert-sentiment-analysis\")\n",
    "bert_output = bert_pipeline(input)\n",
    "\n",
    "print(f\"Bert Output: {bert_output[0]['label']}\")\n",
    "print(f\"Distil Output: {distil_output[0]['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP and tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = \"HOWDY, how aré yoü?\"\n",
    "\n",
    "# Download the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Normalize the input string\n",
    "output = tokenizer.backend_tokenizer.normalizer.normalize_str(input_string)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing tokenizer output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"Pineapple on pizza is pretty good, I guess.\"\n",
    "\n",
    "# Download the gpt tokenizer\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Tokenize the input\n",
    "gpt_tokens = gpt_tokenizer.tokenize(input)\n",
    "\n",
    "# Repeat for distilbert\n",
    "distil_tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "distil_tokens = distil_tokenizer.tokenize(text=input)\n",
    "\n",
    "# Compare the output\n",
    "print(f\"GPT tokenizer: {gpt_tokens}\")\n",
    "print(f\"DistilBERT tokenizer: {distil_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammatical correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "classifier = pipeline(\n",
    "  task=\"text-classification\", \n",
    "  model=\"abdulmatinomotoso/English_Grammar_Checker\"\n",
    ")\n",
    "\n",
    "# Predict classification\n",
    "output = classifier(\"I will walk dog\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Natural Language Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "classifier = pipeline(task=\"text-classification\", model=\"cross-encoder/qnli-electra-base\")\n",
    "\n",
    "# Predict the output\n",
    "output = classifier(\"Where is the capital of France?, Brittany is known for their kouign-amann.\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A 75-million-year-old Gorgosaurus fossil is the first tyrannosaur skeleton ever found with a filled stomach.\"\n",
    "\n",
    "# Build the zero-shot classifier\n",
    "classifier = pipeline(task=\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Create the list\n",
    "candidate_labels = [\"politics\", \"science\", \"sports\"]\n",
    "\n",
    "# Predict the output\n",
    "output = classifier(text, candidate_labels)\n",
    "\n",
    "print(f\"Top Label: {output['labels'][0]} with score: {output['scores'][0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "developing-ai-applications",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
